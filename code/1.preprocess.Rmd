---
title: "pre-process"
author: "Anders Kiledal"
date: "10/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here::here())
```

This document lays out the processing of shotgun metagenomic data from a concrete sample (S3 fallen) collected from an ASR affected brige in Northern New Jersey. A negative control sample was also submitted for sequencing, but it failed to generate a signal.

Several dependencies are required:

  -   fastqc used to assess reads pre- and post-processing
  -   trim-galore! to QC the reads and remove any adapters
  -   bbmap, specifically for bbmerge, used to join paired end reads
  -   metaphlan3, used to taxonomically profile the data

Install dependencies
```{bash}
conda create --name mpa -c bioconda metaphlan bbmap fastqc cutadapt trim-galore
```



Assess read quality
```{bash}
source ~/miniconda2/bin/activate mpa

cd data/raw_sequence_files

mkdir fastqc_reports

fastqc -o fastqc_reports -t 4 *.fastq.gz
```
Process reads with trim-galore
```{bash}
source ~/miniconda2/bin/activate mpa

cd data/raw_sequence_files

trim_galore --paired -o ../qc_sequence_files *.fastq.gz
```
Re-assess read quality
```{bash}
source ~/miniconda2/bin/activate mpa

cd data/qc_sequence_files

mkdir fastqc_reports

fastqc -o fastqc_reports -t 4 *.fq.gz
```

Merge paired end reads
```{r}
library(tidyverse)

system("wsl ~/miniconda2/bin/activate mpa; which bbmerge.sh")

bbmerge_path <- "/home/eandersk/miniconda2/envs/mpa/bin/bbmerge.sh"

system(paste("wsl",bbmerge_path,"--version"))

if ((grep("Windows", osVersion, ignore.case = TRUE))) { #Run on windows subsystem for linux if OS is windows
  bbmerge_path <- paste("wsl",bbmerge_path)
}

fqs <- list.files("data/qc_sequence_files/",pattern = "*.fq.gz")

samples <- fqs %>% str_remove("_S[0-9]_R[0-9]_.*") %>% unique()

files <- data.frame(sample = samples) %>% 
  mutate(forward = paste0("data/qc_sequence_files/",sample,"_S1_R1_001_val_1.fq.gz"),
         reverse = paste0("data/qc_sequence_files/",sample,"_S1_R2_001_val_2.fq.gz"))

for (i in 1:length(files)){
  system(paste0(bbmerge_path,
                " in1=", files$forward[i],
                " in2=", files$reverse[i], 
                " out=", files$sample[i], ".fastq.gz" ,
                " outu1=", files$sample[i], "_F_unmerged.fastq.gz", 
                " outu2=", files$sample[i], "_R_unmerged.fastq.gz"))
}

```

Run metaphlan
```{bash}
source ~/miniconda2/bin/activate mpa

mkdir data/metaphlan

metaphlan data/qc_sequence_files/S3_Fallen_S1_R1_001_val_1.fq,data/qc_sequence_files/S3_Fallen_S1_R2_001_val_2.fq \
  --bowtie2db ~/metaphlan_db \
  --bowtie2out data/metaphlan/metagenome.bowtie2.bz2 \
  --nproc 4 \
  --input_type fastq \
  -o data/metaphlan/S3_fallen_metaphlan.txt

```


```{bash}
source ~/miniconda2/bin/activate mpa

merge_metaphlan_tables.py data/metaphlan/S3_fallen_metaphlan.txt > data/metaphlan/table.tsv

```


## Megan

https://github.com/uhkniazi/HPRU_Metagenomics
```{bash}

cd /work/akiledal/diamond

wget ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz

gunzip nr.gz ; mv nr nr.fasta

diamond makedb --in nr.fa -d nr 





```


Run diamond
```{bash}
date
ssh akiledal@biomix.dbi.udel.edu "sbatch" <<'ENDSSH'
#!/bin/bash
#SBATCH --job-name=diamond_blastx
#SBATCH --chdir=/work/akiledal/diamond
#SBATCH --mem=800G
#SBATCH -c 48
#SBATCH --mail-type=ALL
#SBATCH --mail-user=akiledal@udel.edu
#SBATCH --time=20-0

date
hostname
start=`date +%s`

###Script starts here###

mkdir temp

samples="S3_Fallen_S1_R1_001_val_1 S3_Fallen_S1_R2_001_val_2"

for s in ${samples}
do
    diamond blastx -p 48 -d nr -q ${s}.fastq -a BM_${s} -t temp
done

rm temp

###Script ends here###
echo "Duration: $((($(date +%s)-$start)/60)) minutes"
ENDSSH
```
Use diamond to convert .daa fiels to .m8 files
```{bash}
date
ssh akiledal@biomix.dbi.udel.edu "sbatch" <<'ENDSSH'
#!/bin/bash
#SBATCH --job-name=diamond_m8
#SBATCH --chdir=/work/akiledal/diamond
#SBATCH --mem=800G
#SBATCH -c 48
#SBATCH --mail-type=ALL
#SBATCH --mail-user=akiledal@udel.edu
#SBATCH --time=20-0

date
hostname
start=`date +%s`

###Script starts here###

samples="BM_S3_Fallen_S1_R1_001_val_1 BM_S3_Fallen_S1_R2_001_val_2"

for s in ${samples}
do
    diamond view -a ${s}.daa -o ${s}.m8
done

###Script ends here###
echo "Duration: $((($(date +%s)-$start)/60)) minutes"
ENDSSH
```



BM_samples="BM_003_S1_L001_R1_001 BM_003_S1_L001_R2_001"

for s in ${BM_samples}
do
    ./diamond view -a ${s}.daa -o ${s}.m8
done




## Shogun

### Pre-process with Shi7

Despite claims to the contrary online, it seems to not handle fastq.gz, so files were manually gunzipped beforehand.

```{bash}
shi7 -i for_shi7/ -o shi7_out --adaptor Nextera --flash False --filter_length 50 -m 0
```


Run the Shogun pipeline using bowtie2
```{bash}
shogun pipeline -i combined_seqs.fna -d /work/akiledal/shogun/ -o shogun_output -a bowtie2
```



Plot metacodeR of the Shogun results
```{r}
library(biomformat)
library(tidyverse)
library(qiime2R)
library(readr)
library(metacoder)
library(viridis)

table <- read_tsv("data/shi7_out/shogun_output/taxatable.strain.ra.txt") %>% 
  mutate(S3_fallen = (S3Fallen.S1.R1.R1 + S3Fallen.S1.R1.R2) / 2 ) %>% 
  select(lineage = "#OTU ID",S3_fallen) %>% 
  write_tsv("data/shi7_out/shogun_output/rel_abund.txt") #write the table w/ F & R summarized into one sample

met_samples <- data.frame(sample_id = "S3_fallen", Type = "Concrete")


#Make the MetaCodeR obj
  ##Greengenes class_regex = "^(.+)__(.*)$"
  ##SILVA class_regex = "^D_(.+)__(.*)$"  

obj <- parse_tax_data(table, class_cols = "lineage", class_sep = ";",
                      class_regex = "^(.+)__(.*)$",
                      class_key = c("tax_rank" = "taxon_rank", "name" = "taxon_name"))


## Calculate relative abundance
obj$data$rel_abd <- calc_obs_props(obj, "tax_data", other_cols = T)

#summing per-taxon counts
obj$data$tax_abund <- calc_taxon_abund(obj, "rel_abd",
                                       cols = met_samples$sample_id,
                                       groups = met_samples$Type)

#To get in final relative abundance form
obj$data$tax_abund$Concrete <- obj$data$tax_abund$Concrete / obj$data$tax_abund$Concrete[1]

#Make the heat tree
obj %>%
taxa::filter_taxa(Concrete > 0.01, taxon_ranks == "s", supertaxa = TRUE) %>%
heat_tree(node_label = taxon_names,
          node_size = Concrete,
          node_size_trans = "area",
          node_size_range = c(0.002,0.05),
          node_label_size_range = c(.015,.025),
          node_size_axis_label = "OTU count",
          initial_layout = "reingold-tilford", 
          layout = "davidson-harel",
          #layout = "automatic",
          overlap_avoidance = 5,
          repel_force = 10,
          node_label_max = 50 ,
          node_color = Concrete,
          node_color_range = c("gray80","gray80","gray80"),
          node_color_axis_label = "Relative abundance") +
          ggsave("data/shi7_out/shogun_output/metacodeR.pdf", device = cairo_pdf, units = "in", height = 12, width = 12, dpi = 300) +
          ggsave("data/shi7_out/shogun_output/metacodeR.png", type = "cairo", units = "in", dpi = 300, height = 12, width = 12)
```




